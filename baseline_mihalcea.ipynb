{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some imports and datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from utils import utils_vectorize as uv\n",
    "\n",
    "# Loading datasets\n",
    "with open('datasets/msrpar_txt.pkl', 'rb') as f:    \n",
    "    par_txt_pairs, par_scores = pickle.load(f)\n",
    "with open('datasets/msrvid_txt.pkl', 'rb') as f:    \n",
    "    vid_txt_pairs, vid_scores = pickle.load(f)\n",
    "with open('datasets/msranswer_txt.pkl', 'rb') as f:    \n",
    "    answer_txt_pairs, answer_scores = pickle.load(f)\n",
    "    \n",
    "# DEF2DEF dataset flavors\n",
    "with open('datasets/def2def_txt.pkl', 'rb') as f: \n",
    "    def2def_txt_pairs, def2def_scores = pickle.load(f)\n",
    "with open('datasets/def2def_adjusted_txt.pkl', 'rb') as f: \n",
    "    def2def_adjusted_txt_pairs, def2def_adjusted_scores = pickle.load(f)\n",
    "with open('datasets/def2def250_adjusted_txt.pkl', 'rb') as f: \n",
    "    def2def250_txt_pairs, def2def250_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with trues in a dataset of pairs with Mihalcea similarity function\n",
    "def txt_sents_sim(ds_txt_pairs, true_scores, stop_words=True, punct_marks=False, embed_model='w2v'):\n",
    "    sims = []\n",
    "    for pair in ds_txt_pairs:\n",
    "        sims.append(uv.mihalcea_sim(pair, stop_words=stop_words, punct_marks=punct_marks, embed_model=embed_model))\n",
    "    correlation = np.corrcoef(sims, np.array(true_scores))[0][1]\n",
    "    return(correlation, np.array(sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual datasets tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr. for MSRpar: 0.5633251387251759 \n",
      "\n",
      "Corr. for MSRvid: 0.7119601701442593 \n",
      "\n",
      "Corr. for MSRanswer: 0.498384244352392 \n",
      "\n",
      "Corr. for def2def: 0.4762962028471135 \n",
      "\n",
      "Corr. for def2def_adjusted: 0.5363979457342523 \n",
      "\n",
      "Corr. for def2def_250: 0.5828188187111102 \n",
      "\n",
      "\tCorrelations mean: 0.5615304200857172\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "names = ['MSRpar', 'MSRvid', 'MSRanswer', 'def2def', 'def2def_adjusted', 'def2def_250']\n",
    "sets = [par_txt_pairs, vid_txt_pairs, answer_txt_pairs, def2def_txt_pairs, def2def_adjusted_txt_pairs, def2def250_txt_pairs]\n",
    "true_scores = [par_scores, vid_scores, answer_scores, def2def_scores, def2def_adjusted_scores, def2def250_scores]\n",
    "correlations = []\n",
    "\n",
    "# Test combinations: embedding = ('w2v', 'glove')\n",
    "for idx, elem in enumerate(sets):\n",
    "    scores = true_scores[idx]\n",
    "    corr, sims = txt_sents_sim(elem, scores, stop_words=True, \n",
    "                               punct_marks=False, embed_model='w2v')   \n",
    "    correlations.append(corr)\n",
    "   # print('True scores min, max, mean and std:',np.min(scores), np.max(scores), np.mean(scores), np.std(scores))\n",
    "   # print('Sim scores min, max, mean and std:', np.min(sims*5), np.max(sims*5), np.mean(sims*5), np.std(sims*5))\n",
    "    print('Corr. for', names[idx]+':', corr, '\\n')\n",
    "print('\\tCorrelations mean:', np.mean(np.array(correlations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unified datasets tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With original DEF2DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified dataset size: 3747\n",
      "Correlation: 0.32799052627820124\n"
     ]
    }
   ],
   "source": [
    "# New unified datasets: 80% of samples and 83% of triplets are from DEF2DEF if original dataset\n",
    "sent_txt_samples = par_txt_pairs + vid_txt_pairs + answer_txt_pairs + def2def_txt_pairs\n",
    "scores = par_scores + vid_scores + answer_scores + [score/10 for score in def2def_scores]   # def2def scores 0-50 -> 0-5\n",
    "print('Unified dataset size:', len(sent_txt_samples))\n",
    "\n",
    "# Main: presents correlation and additional info\n",
    "corr, sims = txt_sents_sim(sent_txt_samples, scores, stop_words=True, punct_marks=False, embed_model='w2v')   \n",
    "\n",
    "#print('True scores min, max, mean and std:',np.min(scores), np.max(scores), np.mean(scores), np.std(scores))\n",
    "#print('Sim scores min, max, mean and std:', np.min(sims*5), np.max(sims*5), np.mean(sims*5), np.std(sims*5))\n",
    "print('Correlation:', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With adjusted DEF2DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified dataset size: 3044\n",
      "Correlation: 0.3653456542028317\n"
     ]
    }
   ],
   "source": [
    "sent_txt_samples = par_txt_pairs + vid_txt_pairs + answer_txt_pairs + def2def_adjusted_txt_pairs\n",
    "scores = par_scores + vid_scores + answer_scores + [score/10 for score in def2def_adjusted_scores]   # def2def scores 0-50 -> 0-5\n",
    "print('Unified dataset size:', len(sent_txt_samples))\n",
    "\n",
    "# Main: presents correlation and additional info\n",
    "corr, sims = txt_sents_sim(sent_txt_samples, scores, stop_words=True, punct_marks=False, embed_model='w2v')   \n",
    "\n",
    "#print('True scores min, max, mean and std:',np.min(scores), np.max(scores), np.mean(scores), np.std(scores))\n",
    "#print('Sim scores min, max, mean and std:', np.min(sims*5), np.max(sims*5), np.mean(sims*5), np.std(sims*5))\n",
    "print('Correlation:', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With DEF2DEF_250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unified dataset size: 1004\n",
      "Correlation: 0.41758350498863467\n"
     ]
    }
   ],
   "source": [
    "sent_txt_samples = par_txt_pairs + vid_txt_pairs + answer_txt_pairs + def2def250_txt_pairs\n",
    "scores = par_scores + vid_scores + answer_scores + [score/10 for score in def2def250_scores]   # def2def scores 0-50 -> 0-5\n",
    "print('Unified dataset size:', len(sent_txt_samples))\n",
    "\n",
    "# Main: presents correlation and additional info\n",
    "corr, sims = txt_sents_sim(sent_txt_samples, scores, stop_words=True, punct_marks=False, embed_model='w2v')   \n",
    "\n",
    "#print('True scores min, max, mean and std:',np.min(scores), np.max(scores), np.mean(scores), np.std(scores))\n",
    "#print('Sim scores min, max, mean and std:', np.min(sims*5), np.max(sims*5), np.mean(sims*5), np.std(sims*5))\n",
    "print('Correlation:', corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_refs = [0.42, 0.82, 0.52, 0.53]   # -> mean = .57 | W2V + BEST STR + F.INF + COS\n",
    "\n",
    "# Individual datasets with Mihalcea similarity | This file: ok 20250425 | Rechecked 20250616\n",
    "MSRpar =    [0.563]\n",
    "MSRvid =    [0.712]\n",
    "MSRanswer = [0.498]\n",
    "def2def =   [0.476]           # Corr. mean=0.57\n",
    "def2def_adjusted = [0.536]    # Corr. mean=0.58\n",
    "def2def250_adjusted = [0.583] # Corr. mean=0.59\n",
    "\n",
    "# Unified datasets with Mihalcea similarity | This file: ok 20250502 | Rechecked 20250616\n",
    "with_original_DEF2DEF = [0.328]\n",
    "with_adjusted_DEF2DEF = [0.365]\n",
    "with_DEF2DEF_250      = [0.418]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
